{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595984625812",
   "display_name": "Python 3.7.6 64-bit ('ai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package cess_esp to\n[nltk_data]     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package cess_esp is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_Águila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japonés', 'Mitsubishi_Corporation', 'para', 'poner_en_marcha', 'una', 'central', 'de', 'gas', 'de', '495', 'megavatios', '.'], ['Una', 'portavoz', 'de', 'EDF', 'explicó', 'a', 'EFE', 'que', 'el', 'proyecto', 'para', 'la', 'construcción', 'de', 'Altamira_2', ',', 'al', 'norte', 'de', 'Tampico', ',', 'prevé', 'la', 'utilización', 'de', 'gas', 'natural', 'como', 'combustible', 'principal', 'en', 'una', 'central', 'de', 'ciclo', 'combinado', 'que', 'debe', 'empezar', 'a', 'funcionar', 'en', 'mayo_del_2002', '.'], ...]\n"
    }
   ],
   "source": [
    "corpus = nltk.corpus.cess_esp.sents()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CESS-ESP and CESS-CAT TREEBANK\n\nThe Universitat de Barcelona (CLiC-UB), the Universidad de Alicante\n(UA), the Universitat PolitÃšcnica de Catalunya (UPC), and the Euskal\nHerriko Unibertsitatea (EHU-UPV) are the sole and exclusive owners of\nthe CESS-Esp treebank.  Information for this corpus can be found at:\nhttp://www.lsi.upc.edu/~mbertran/cess-ece2/\n\nThe goal of the CESS-ECE project is to create three corpora, one for\nSpanish (CESS-ESP), one for Catalan (CESS-Cat) and one for Basque\n(CESS-EUS), of 500,000 words for CESS-Esp and CESS-Cat and 350,000\nwords for the CESS-Eus. These corpora will be tagged in two ways:\nsyntactically (with constituents and functions for CESS-Esp and\nCESS-Cat and with dependencies for CESS-Eus) and semantically (with\nWordNet synsets). This project is based on resources from 3LB Project\n(FIT 150500-2002-244), where 100,000 words per language were annotated\nin the same way.\n\nThe version distributed with NLTK are syntactic treebanks (with\nconstituents and functions) consisting of 1377 files for Catalan and\n610 for Spanish. They are treebanks (with POS and lemma) with a fairly\ncomplete tagset documented on the project's website.\n\nA sample tree for Spanish:\n\n(\n (S\n   (snp-SUJ\n     (espec.ms\n       (da0ms0 El el))\n     (grup.nom.ms\n       (ncms000 pÃºgil pÃºgil)\n       (s.a.ms\n         (grup.a.ms\n           (aq0cs0 estadounidense estadounidense)))\n       (snp\n         (grup.nom.ms\n           (np0000p Will_\"Steel\"_Grigsby Will_\"Steel\"_Grigsby)))))\n   (grup.verb\n     (vmis3s0 conquistÃ³ conquistar))\n   (sn-CCT\n     (espec.fs\n       (dd0fs0 esta este))\n     (grup.nom.fs\n       (ncfs000 tarde tarde)))\n....\n\nIn the Spanish corpus, files with an initial letter correspond to\ndifferent genres (only those from the original 3LB sample):\n\n       A       press: articulistas     PRESS: OPINION\n       E       press: ensayo   PRESS:ESSAY\n       C       press: suplementosCiencia       PRESS: SCIENCE SUPLEMENT\n       D       press: prensa deportiva         PRESS: SPORTS\n       N       press: noticias         PRESS:NEWS\n       R       press: semanarios       PRESS: WEEKLIES,\n       T       fiction: narrativa      FICTION: NARRATIVE\n\nCESS-ECE corpora should allow both grammar inference for syntactic\nparsing and the training of Machine Learnig systems for word sense\ndisambiguation.\n\nIf you use these corpora for research, please cite thusly: CESS-Cat\nproject (M. Antonia MartÃ­, MarionaTaulÃ©, LluÃ­s MÃ¡rquez, Manuel\nBertran (2007) ?CESS-ECE: A Multilingual and Multilevel Annotated\nCorpus? in http://www.lsi.upc.edu/~mbertran/cess-ece/publications).\n\n"
    }
   ],
   "source": [
    "len(corpus)\n",
    "print(nltk.corpus.cess_esp.readme())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "192685\n['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_Águila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japonés', 'Mitsubishi_Corporation']\n"
    }
   ],
   "source": [
    "flatten = [word for line in corpus for word in line]\n",
    "\n",
    "print(len(flatten))\n",
    "print(flatten[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_words(words_list, pattern, limit):\n",
    "    search = re.compile(pattern)\n",
    "    count = 0\n",
    "    \n",
    "    for word in words_list:\n",
    "        if limit == count:\n",
    "            break\n",
    "\n",
    "        if search.search(word):\n",
    "            yield word\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nes\n\n ['estatal', 'jueves', 'empresa', 'centrales', 'francesa', 'japonesa', 'millones', 'millones', 'dólares', 'millones']\n\n\nes$\n\n ['jueves', 'centrales', 'millones', 'millones', 'dólares', 'millones', 'millones', 'dólares', 'es', 'militantes']\n\n\n^..j..t..$\n\n ['tajantes']\n\n\n^[ghi][mno][jlk][def]$\n\n ['golf', 'golf']\n\n\n^(no)*\n\n ['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',']\n\n\n(no)+\n\n ['norte', 'no', 'no', 'noche', 'no', 'no', 'gobierno', 'notificación', 'Unión_Fenosa_Inversiones', 'italiano']\n"
    }
   ],
   "source": [
    "def print_search(words_list, pattern, limit=10):\n",
    "    print(f'\\n\\n{pattern}\\n\\n', list(search_words(words_list, pattern, limit)))\n",
    "\n",
    "print_search(flatten, r'es')\n",
    "print_search(flatten, r'es$')\n",
    "print_search(flatten, r'^..j..t..$')\n",
    "print_search(flatten, r'^[ghi][mno][jlk][def]$')\n",
    "print_search(flatten, r'^(no)*')\n",
    "print_search(flatten, r'(no)+')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split / tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cuando sea el rey del mundo  (imaginaba él en su cabeza) no tendré que  preocuparme por estas bobadas. \n            Era solo un niño de 7 años, pero pensaba que podría ser cualquier cosa que su imaginación le permitiera visualizar en su cabeza ...\n"
    }
   ],
   "source": [
    "txt = \"\"\" Cuando sea el rey del mundo  (imaginaba él en su cabeza) no tendré que  preocuparme por estas bobadas. \n",
    "            Era solo un niño de 7 años, pero pensaba que podría ser cualquier cosa que su imaginación le permitiera visualizar en su cabeza ...\"\"\"\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', '(imaginaba', 'él', 'en', 'su', 'cabeza)', 'no', 'tendré', 'que', 'preocuparme', 'por', 'estas', 'bobadas.', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años,', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '...']\n"
    }
   ],
   "source": [
    "print(re.split(r'\\s+', txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', 'imaginaba', 'él', 'en', 'su', 'cabeza', 'no', 'tendré', 'que', 'preocuparme', 'por', 'estas', 'bobadas', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '']\n"
    }
   ],
   "source": [
    "print(re.split(r'[\\W\\s]+', txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "En los E.U. esa postal vale $15.50 ...\n"
    }
   ],
   "source": [
    "# nuestra antigua regex no funciona en este caso: \n",
    "txt = 'En los E.U. esa postal vale $15.50 ...'\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['En', 'los', 'E', 'U', 'esa', 'postal', 'vale', '15', '50', '']\n"
    }
   ],
   "source": [
    "print(re.split(r'[\\W\\s]+', txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['En', 'los', 'E.U.', 'esa', 'postal', 'vale', '$15.50', '...']"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "pattern = r'''(?x)                 # set flag to allow verbose regexps\n",
    "              (?:[A-Z]\\.)+         # abbreviations, e.g. U.S.A.\n",
    "              | \\w+(?:-\\w+)*       # words with optional internal hyphens\n",
    "              | \\$?\\d+(?:\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
    "              | \\.\\.\\.             # ellipsis\n",
    "              | [][.,;\"'?():-_`]   # these are separate tokens; includes ], [\n",
    "'''\n",
    "\n",
    "nltk.regexp_tokenize(txt, pattern)\n"
   ]
  }
 ]
}