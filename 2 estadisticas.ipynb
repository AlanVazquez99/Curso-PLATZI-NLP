{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596043924837",
   "display_name": "Python 3.7.6 64-bit ('ai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading collection 'book'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package brown to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package chat80 to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package nps_chat to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package names to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package ppattach to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package reuters to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package senseval to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package state_union to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package swadesh to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package timit to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package toolbox to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package udhr to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package webtext to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package punkt to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package tagsets to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     C:\\Users\\alanv\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection book\n*** Introductory Examples for the NLTK Book ***\nLoading text1, ..., text9 and sent1, ..., sent9\nType the name of the text or sentence to view it.\nType: 'texts()' or 'sents()' to list the materials.\ntext1: Moby Dick by Herman Melville 1851\ntext2: Sense and Sensibility by Jane Austen 1811\ntext3: The Book of Genesis\ntext4: Inaugural Address Corpus\ntext5: Chat Corpus\ntext6: Monty Python and the Holy Grail\ntext7: Wall Street Journal\ntext8: Personals Corpus\ntext9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('book')\n",
    "from nltk.book import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Text: Moby Dick by Herman Melville 1851>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "260819\n['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.']\n"
    }
   ],
   "source": [
    "print(len(text1))\n",
    "print(text1.tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medida de riqueza lexica en un texto: \n",
    "$$ R_l = \\frac{\\text{total de palabras Ãºnicas}}{\\text{total de palabras}} = \\frac{\\text{longitud del vocabulario}}{\\text{longitud del texto}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Moby Dick by Herman Melville 1851 \n 7.406 % \n\nSense and Sensibility by Jane Austen 1811 \n 4.826 % \n\nThe Book of Genesis \n 6.23 % \n\nInaugural Address Corpus \n 6.618 % \n\nChat Corpus \n 13.477 % \n\nMonty Python and the Holy Grail \n 12.766 % \n\nWall Street Journal \n 12.325 % \n\nPersonals Corpus \n 22.766 % \n\nThe Man Who Was Thursday by G . K . Chesterton 1908 \n 9.835 % \n\n"
    }
   ],
   "source": [
    "def lexical_affluence(corpus):\n",
    "    vocabulary = sorted(set(corpus))\n",
    "    return len(vocabulary) / len(corpus)\n",
    "\n",
    "texts = [ i for i in dir(nltk.book) if re.search(r'text\\d', i)]\n",
    "for text in texts:\n",
    "    exec(compile(f'print({text}.name, \"\\\\n\", round(100*lexical_affluence({text}),3), \"%\", \"\\\\n\" )', \n",
    "        '', 'exec'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'5.53%'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "def word_percentage(word, corpus):\n",
    "    count = 0\n",
    "    transforms = { \n",
    "        word,\n",
    "        word.lower(),\n",
    "        word.upper(),\n",
    "        word.capitalize()\n",
    "    }\n",
    "\n",
    "    for transform in transforms:\n",
    "        count += corpus.count(transform)\n",
    "\n",
    "    return count / len(corpus)\n",
    "\n",
    "'{:.2%}'.format(word_percentage('the', text1))"
   ]
  }
 ]
}